---
layout: post
title:  "프로젝트 03. 로또번호 크롤링 및 엑셀저장"
date:   2019-04-24 01:06:23 +0700
categories: [프로젝트]
---

### 2019.04.24 로또번호 크롤링 및 엑셀에 저장하기

\# 질문에 답하기

1. request란?
2. BeautifulSoup4의 역할
 
# 목표
* 다음에서 로또번호를 검색하여 1등 당첨번호를 크롤링한다
* 회차를 늘려 1회부터 855회(현재)까지 크롤링을 완료한다.
* 크롤링한 정보를 엑셀에 넣어 저장한다.

## 구현

```python
import requests            #웹사이트에 접속, 데이터를 받아오는 역할
from bs4 import BeautifulSoup            #데이터를 HTML로 해석하는 역할
from openpyxl import Workbook

# 크롤링 방지를 위해 구현 (마치 사람이 접속하는 것 처럼 보이도록)
custom_header = {
    'referer' : 'https://www.naver.com',
    'user-agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36'   

wb = Workbook        #Workbook 생성
ws1 = wb.active        #활성시트 생성

for num in range(1, 856):
    #매번 크롤링 해야하는 url을 바꿔준다. 중간에 string 행태로 들어가서 주소가 완성되어야 한다.
    url = "https://search.daum.net/search?w=tot&rtmaxcoll=LOT&DA=LOT&q="+str(num)+"%ED%9A%8C%EC%B0%A8%20%EB%A1%9C%EB%98%90"
    a = str(num) + "회차정보"
    ws1.cell(row=num, column=1, value=a)    #1열에 몇회차인지 쭉 나열해서 적는다.
    req = requests.get(url)                            #해당 url의 데이터 정보를 받아온다.
    count = 2     #1열은 사용하였기 때문에 2열부터 번호 저장
    if req.status_code == requests.codes.ok:             #접속이 안정적으로 되었다면
        html = BeautifulSoup(req.text, "html.parser")         #불러온 데이터를 HTML로 해석한다.
        numbers = html.select(".lottonum .img_lotto")        #select를 통해 class lottonum 아래의 class img_lotto를 크롤링
        for number in numbers[:6]:      #보너스 번호 제외
            ws1.cell(row=num, column=count, value=number.text)    #2번째 열부터 값을 입력
            count += 1
            print(number.text, end = "   ")

wb.save("로또번호.xlsx")
```

* 정적페이지의 크롤링에 적합한 beautifulSoup parser
* excel파일 정보 입력
	* 한 셀에 정보 입력하기
	* ws.cell(row = 1, column = 1, value = "1") 	